# DEEP-learning notes
###################
#    LECTURE 1   #
###################
Unknown terms
_____________________________________________
*receptive field
*advance convolutions
*pose estimation
*super resolution
*Super convergence
*Yolo V2 architecture:loss function
*Masked RCNN
*GAN's VAR
*latent vector: make person look old with condition
*Optimizers:adam, adagrad, HDD with momentum 
*ReLu PreLu PRELU
*transfer learning
_______________________________________________________________ 
Segmentation:boundry around an object
Mask: mask around an object(sillhoute structure)
Fully connected layer:obsolete

Channels:An instrument in an orchestra,All the e's 1 channel e channel 
Channel is a blue print that contains all the information that 
e channel container of a very specific information
each channel containes very specific
e is a feature, full channel: feature map (all the e's)
what extracts e : feature extractor,kernel,filter, 3*3 matrix
output of the channel is the output of the festure extractor


Gradient:color changing from 1 to another
4 layers; edges combine to make texture -> pattern ->parts of objects-> objects

Network should see the whole picture
Recprive field of the last layer must atleast be the size of the object youre looking at
global receptive field of the last layer must be the size of the object
panning:going outside the image copy of last pixel
max pooling
functional API
 
Convolution


_____________________________________________________________
Resources
Andrev karpati
sanity archive



 
